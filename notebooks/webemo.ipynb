{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(sys.path[0].replace('notebooks', 'src'))\n",
    "\n",
    "import modeling.modeling_utils as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0+cu121'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.torch.cuda.is_available() # Check for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "device = m.torch.device(\"cuda\" if m.torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "m.torch.backends.cudnn.benchmark=True # Helps optimize training w/ GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The WEBEmo dataset is fairly massive and unable to be uploaded. The ```image-gather``` notebook can be used to download all images, and this notebook contains the code to train a model using curriculum learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train, test = m.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>file</th>\n",
       "      <th>lvl_three</th>\n",
       "      <th>lvl_one</th>\n",
       "      <th>lvl_two</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1_220_F_83683073_O4yJOnarzTjKXuUBAgkAifmiC8d0I...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20_220_F_5292725_818KTy3xv82nEkNolcs2m37MOV86s...</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20_220_F_47187567_lwYwc9UQtBK5Be6v4P7HNsCc4Hhr...</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1_220_F_38932828_Osns7NBWCq8AhJonYpQArrToDLLhT...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1_220_F_97168737_y0VWy7kLMby9BO6lHDfpyfNpW9o0S...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               file  lvl_three  \\\n",
       "0           0  1_220_F_83683073_O4yJOnarzTjKXuUBAgkAifmiC8d0I...          1   \n",
       "1           1  20_220_F_5292725_818KTy3xv82nEkNolcs2m37MOV86s...         20   \n",
       "2           2  20_220_F_47187567_lwYwc9UQtBK5Be6v4P7HNsCc4Hhr...         20   \n",
       "3           3  1_220_F_38932828_Osns7NBWCq8AhJonYpQArrToDLLhT...          1   \n",
       "4           4  1_220_F_97168737_y0VWy7kLMby9BO6lHDfpyfNpW9o0S...          1   \n",
       "\n",
       "   lvl_one  lvl_two  \n",
       "0        0        0  \n",
       "1        1        1  \n",
       "2        1        1  \n",
       "3        0        0  \n",
       "4        0        0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5001"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Level 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<br>\n",
    "For training, I split the data into 90/10 train/validation sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train_split, val_split = m.train_val_split(X=train['file'], \n",
    "                                           y=train['lvl_one'], \n",
    "                                           test_size=.1, \n",
    "                                           random_state=713)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Pytorch has some pretty neat classes to help load in data. First, I define the transforms that will be used as photos are iteratively loaded during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train_transforms = m.transforms.Compose([m.transforms.Resize(256),\n",
    "                                         m.transforms.RandomCrop(224),\n",
    "                                         m.transforms.ToTensor(),\n",
    "                                         m.transforms.Normalize(mean=[0.485, 0.456, 0.406], #OG means/sds from imagenet\n",
    "                                                                std=[0.229, 0.224, 0.225])\n",
    "                                        ])\n",
    "val_transforms = m.transforms.Compose([m.transforms.Resize(256),\n",
    "                                       m.transforms.CenterCrop(224),\n",
    "                                       m.transforms.ToTensor(),\n",
    "                                       m.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                              std=[0.229, 0.224, 0.225])\n",
    "                                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Put data into Pytorch Dataset class\n",
    "l1_train_dataset = m.ImgDataset(df=train_split,\n",
    "                                root_dir='../data/images/train',\n",
    "                                percent_sample=1,\n",
    "                                transform=train_transforms)\n",
    "l1_val_dataset = m.ImgDataset(df=val_split,\n",
    "                              root_dir='../data/images/train',\n",
    "                              percent_sample=1,\n",
    "                              transform=val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Pytorch DataLoader iteratively loads minibatches during training\n",
    "l1_loaders = {'train': m.DataLoader(l1_train_dataset,\n",
    "                               batch_size=32, \n",
    "                               shuffle=True,\n",
    "                               #pin_memory=True, # Only use pin_memory with GPU\n",
    "                               num_workers=4), \n",
    "              'val': m.DataLoader(l1_val_dataset, \n",
    "                             batch_size=32,\n",
    "                             #pin_memory=True,\n",
    "                             num_workers=4)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "I used the ```resnet50``` model from Pytorch as the base for the first level. While the pretrained weights were loaded to initialize training, I didn't freeze any layers. That is, I fine-tuned the ```resnet50``` model instead of using it purely for feature extraction. \n",
    "\n",
    "The ```resnet50``` fully-connected classifier layer is of the form ```(input-features, output classes)```, with the original ```output classes``` being 1000 for imagenet; this is simply changed to 2 for the first level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MY PC\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\MY PC\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Get everything set up\n",
    "l1_model = m.models.resnet50(pretrained=True)\n",
    "num_ftrs = l1_model.fc.in_features\n",
    "l1_model.fc = m.nn.Linear(num_ftrs, 2) \n",
    "l1_model = l1_model.to(device)\n",
    "l1_criterion = m.nn.CrossEntropyLoss().to(device)\n",
    "l1_optim = m.torch.optim.SGD(l1_model.parameters(), \n",
    "                                   lr=0.01, \n",
    "                                   momentum=0.9, \n",
    "                                   weight_decay=0.0001)\n",
    "# Lower learning rate after 5 epochs of no validation loss\n",
    "l1_scheduler = lr_scheduler.ReduceLROnPlateau(l1_optim, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/2\n",
      "----------\n",
      "train Loss: 0.6025 Acc: 0.6784\n",
      "val Loss: 0.6866 Acc: 0.5808\n",
      "saving model - best loss\n",
      "0.602476218117608\n",
      "0.6866253315807579\n",
      "tensor(0.6784, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.5808, device='cuda:0', dtype=torch.float64)\n",
      "logs.csv\n",
      "\n",
      "Epoch 1/2\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\fiverr\\Garry_deol_eye_tracking\\emotion_prediction\\Pixels-to-Feelings\\src\\modeling\\modeling_utils.py:314: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log_df = log_df.append(pd.DataFrame({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5632 Acc: 0.7047\n",
      "val Loss: 0.7425 Acc: 0.5948\n",
      "EarlyStopping counter: 1 out of 10\n",
      "0.5632485968536801\n",
      "0.7424675071548797\n",
      "tensor(0.7047, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.5948, device='cuda:0', dtype=torch.float64)\n",
      "logs.csv\n",
      "\n",
      "Epoch 2/2\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\fiverr\\Garry_deol_eye_tracking\\emotion_prediction\\Pixels-to-Feelings\\src\\modeling\\modeling_utils.py:314: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log_df = log_df.append(pd.DataFrame({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5250 Acc: 0.7376\n",
      "val Loss: 0.8201 Acc: 0.5888\n",
      "EarlyStopping counter: 2 out of 10\n",
      "0.5250270613034567\n",
      "0.8201097339213251\n",
      "tensor(0.7376, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.5888, device='cuda:0', dtype=torch.float64)\n",
      "logs.csv\n",
      "\n",
      "Training complete in 3m 10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\fiverr\\Garry_deol_eye_tracking\\emotion_prediction\\Pixels-to-Feelings\\src\\modeling\\modeling_utils.py:314: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log_df = log_df.append(pd.DataFrame({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val Acc: 0.580838\n",
      "Logs saved to ../models/l1model.tar_logs.csv\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "l1_model_train = m.train_model(model=l1_model, \n",
    "                             dataloader=l1_loaders, \n",
    "                             criterion=l1_criterion, \n",
    "                             optimizer=l1_optim,\n",
    "                             save_path='../models/l1model.tar',\n",
    "                             num_epochs=3,\n",
    "                             scheduler=l1_scheduler,\n",
    "                             early_stopping=m.EarlyStopping(patience=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Level 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The idea behind curriculum learning is to sequentially expose the model to more complex discriminative tasks in increasing difficulty. Level 2 contains the exact same images, but now, there are 6 classes to predict. Below, the level 1 model is initialized, and only 2 things are different from the level 1 training:\n",
    "1. The learning rate is 1/10 that of level 1 (i.e., 0.001 instead of 0.01)\n",
    "2. The fully-connected layers are modified to classify level 2 labels (i.e., 6 instead of 2 possibilities)\n",
    "<br>\n",
    "\n",
    "First, I make new dataset/dataloader classes for the level-2 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "l2_train_split = train_split.merge(train, left_on = 'file', right_on = 'file')[['file', 'lvl_two']]\n",
    "l2_val_split = val_split.merge(train, left_on = 'file', right_on = 'file')[['file', 'lvl_two']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "l2_train_dataset = m.ImgDataset(df=l2_train_split,\n",
    "                                root_dir='../data/images/train',\n",
    "                                percent_sample=1,\n",
    "                                transform=train_transforms)\n",
    "l2_val_dataset = m.ImgDataset(df=l2_val_split,\n",
    "                              root_dir='../data/images/train',\n",
    "                              percent_sample=1,\n",
    "                              transform=val_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The level-2 and level-3 data also suffer from class imbalance. To deal with that during training, I use Pytorch's ```WeightedRandomSampler```. By assigning weights to each class, the minibatches become approximately evenly distributed among the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "l2_samples_weights = m.weighted_sample(l2_train_split, 'lvl_two')\n",
    "l2_weighted_sampler = m.WeightedRandomSampler(weights=l2_samples_weights, num_samples=len(l2_samples_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "l2_loaders = {'train': m.DataLoader(l2_train_dataset,\n",
    "                                    batch_size=32, \n",
    "                                    sampler=l2_weighted_sampler,\n",
    "                                    #pin_memory=True, \n",
    "                                    num_workers=4),\n",
    "              'val': m.DataLoader(l2_val_dataset, \n",
    "                             batch_size=32,\n",
    "                             #pin_memory=True,\n",
    "                             num_workers=4)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Initialize model \n",
    "l2_model = m.load_model(path='../models/l1model.tar', \n",
    "                        base=m.models.resnet50(pretrained=False), \n",
    "                        old_classes=2, \n",
    "                        new_classes=6, \n",
    "                        device=device)\n",
    "l2_criterion = m.nn.CrossEntropyLoss().to(device)\n",
    "l2_optim = m.torch.optim.SGD(l2_model.parameters(), \n",
    "                                   lr=0.001, \n",
    "                                   momentum=0.9, \n",
    "                                   weight_decay=0.0001)\n",
    "l2_scheduler = lr_scheduler.ReduceLROnPlateau(l2_optim, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1\n",
      "----------\n",
      "train Loss: 1.7523 Acc: 0.2289\n",
      "val Loss: 1.7779 Acc: 0.2196\n",
      "saving model - best loss\n",
      "1.7522641068564522\n",
      "1.7779437163156901\n",
      "tensor(0.2289, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.2196, device='cuda:0', dtype=torch.float64)\n",
      "logs.csv\n",
      "\n",
      "Epoch 1/1\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\fiverr\\Garry_deol_eye_tracking\\emotion_prediction\\Pixels-to-Feelings\\src\\modeling\\modeling_utils.py:314: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log_df = log_df.append(pd.DataFrame({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.6312 Acc: 0.2871\n",
      "val Loss: 1.7849 Acc: 0.2635\n",
      "EarlyStopping counter: 1 out of 10\n",
      "1.6312431082195706\n",
      "1.784878307949759\n",
      "tensor(0.2871, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.2635, device='cuda:0', dtype=torch.float64)\n",
      "logs.csv\n",
      "\n",
      "Training complete in 2m 12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\fiverr\\Garry_deol_eye_tracking\\emotion_prediction\\Pixels-to-Feelings\\src\\modeling\\modeling_utils.py:314: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log_df = log_df.append(pd.DataFrame({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val Acc: 0.219561\n",
      "Logs saved to ../models/l2model.tar_logs.csv\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "l2_model_train = m.train_model(model=l2_model, \n",
    "                             dataloader=l2_loaders, \n",
    "                             criterion=l2_criterion, \n",
    "                             optimizer=l2_optim,\n",
    "                             save_path='../models/l2model.tar',\n",
    "                             num_epochs=2,\n",
    "                             scheduler=l2_scheduler,\n",
    "                             early_stopping=m.EarlyStopping(patience=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Level 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The procedural modifications from level 2 to level 3 are minimal. I still make new dataset/dataloader classes, a weighted sampler, and initialize from the optimal model 2. There are only 2 major changes:\n",
    "1. The learning rate is lowered to 0.0001\n",
    "2. The fully-connected layer now outputs 25 instead of 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "l3_train_split = train_split.merge(train, left_on = 'file', right_on = 'file')[['file', 'lvl_three']]\n",
    "l3_val_split = val_split.merge(train, left_on = 'file', right_on = 'file')[['file', 'lvl_three']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "l3_train_dataset = m.ImgDataset(df=l3_train_split,\n",
    "                                root_dir='../data/images/train',\n",
    "                                percent_sample=1,\n",
    "                                transform=train_transforms)\n",
    "l3_val_dataset = m.ImgDataset(df=l3_val_split,\n",
    "                              root_dir='../data/images/train',\n",
    "                              percent_sample=1,\n",
    "                              transform=val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "l3_samples_weights = m.weighted_sample(l3_train_split, 'lvl_three')\n",
    "l3_weighted_sampler = m.WeightedRandomSampler(weights=l3_samples_weights, num_samples=len(l3_samples_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "l3_loaders = {'train': m.DataLoader(l3_train_dataset,\n",
    "                               batch_size=32, \n",
    "                               sampler=l3_weighted_sampler,\n",
    "                               #pin_memory=True,\n",
    "                               num_workers=4),\n",
    "              'val': m.DataLoader(l3_val_dataset, \n",
    "                             batch_size=32,\n",
    "                             #pin_memory=True,\n",
    "                             num_workers=4)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MY PC\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\MY PC\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "l3_model = m.load_model(path='../models/l2model.tar', \n",
    "                        base=m.models.resnet50(pretrained=False), \n",
    "                        old_classes=6, \n",
    "                        new_classes=25, \n",
    "                        device=device)\n",
    "l3_criterion = m.nn.CrossEntropyLoss().to(device)\n",
    "l3_optim = m.torch.optim.SGD(l3_model.parameters(), \n",
    "                                   lr=0.0001, \n",
    "                                   momentum=0.9, \n",
    "                                   weight_decay=0.0001)\n",
    "l3_scheduler = lr_scheduler.ReduceLROnPlateau(l3_optim, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1\n",
      "----------\n",
      "train Loss: 3.2189 Acc: 0.0422\n",
      "val Loss: 3.2143 Acc: 0.0399\n",
      "saving model - best loss\n",
      "3.2189214600457086\n",
      "3.2142922292926355\n",
      "tensor(0.0422, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0399, device='cuda:0', dtype=torch.float64)\n",
      "logs.csv\n",
      "\n",
      "Epoch 1/1\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\fiverr\\Garry_deol_eye_tracking\\emotion_prediction\\Pixels-to-Feelings\\src\\modeling\\modeling_utils.py:314: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log_df = log_df.append(pd.DataFrame({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 3.2112 Acc: 0.0540\n",
      "val Loss: 3.2095 Acc: 0.0339\n",
      "saving model - best loss\n",
      "3.211155111948649\n",
      "3.2094635002151457\n",
      "tensor(0.0540, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0339, device='cuda:0', dtype=torch.float64)\n",
      "logs.csv\n",
      "\n",
      "Training complete in 2m 6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\fiverr\\Garry_deol_eye_tracking\\emotion_prediction\\Pixels-to-Feelings\\src\\modeling\\modeling_utils.py:314: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log_df = log_df.append(pd.DataFrame({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val Acc: 0.033932\n",
      "Logs saved to ../models/l3model.tar_logs.csv\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "l3_model_train = m.train_model(model=l3_model, \n",
    "                             dataloader=l3_loaders, \n",
    "                             criterion=l3_criterion, \n",
    "                             optimizer=l3_optim,\n",
    "                             save_path='../models/l3model.tar',\n",
    "                             num_epochs=2,\n",
    "                             scheduler=l3_scheduler,\n",
    "                             early_stopping=m.EarlyStopping(patience=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 0\n",
      "Class probabilities: tensor([[0.7555, 0.2445]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define a function to predict an image using the trained model\n",
    "def predict_image(model, image_path, transforms, device):\n",
    "    \"\"\"\n",
    "    Predict the class of a single image.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): Trained PyTorch model.\n",
    "        image_path (str): Path to the image file.\n",
    "        transforms (torchvision.transforms.Compose): Transformations to apply to the image.\n",
    "        device (torch.device): Device to use for computation.\n",
    "\n",
    "    Returns:\n",
    "        int: Predicted class label.\n",
    "        torch.Tensor: Class probabilities.\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    \n",
    "    # Apply transformations\n",
    "    image_tensor = transforms(image).unsqueeze(0)  # Add batch dimension\n",
    "    \n",
    "    # Move the image tensor to the specified device\n",
    "    image_tensor = image_tensor.to(device)\n",
    "    \n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Disable gradient calculations for inference\n",
    "    with torch.no_grad():\n",
    "        # Get predictions\n",
    "        outputs = model(image_tensor)\n",
    "        \n",
    "        # Convert logits to probabilities\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        \n",
    "        # Get the predicted class\n",
    "        predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "    \n",
    "    return predicted_class, probabilities\n",
    "\n",
    "# Specify the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Path to the image\n",
    "image_path = \"E:\\\\fiverr\\\\Garry_deol_eye_tracking\\\\emotion_prediction\\\\Pixels-to-Feelings\\\\data\\\\images\\\\test\\\\0_220_F_24870_DFd91XhrsOYD0OXCMWgLV9ggisNCrs.jpg\"\n",
    "\n",
    "# Predict the image\n",
    "predicted_class, probabilities = predict_image(\n",
    "    model=l1_model,\n",
    "    image_path=image_path,\n",
    "    transforms=val_transforms,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Display the result\n",
    "print(f\"Predicted class: {predicted_class}\")\n",
    "print(f\"Class probabilities: {probabilities}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
